{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdmYtTpqyKZp7RG000swKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalijadhav002/Zeotap_Datascience_Task/blob/main/Anjali_Jadhav_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g6axzZK5H4p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "customers = pd.read_csv('Customers.csv')\n",
        "transactions = pd.read_csv('Transactions.csv')\n",
        "\n",
        "\n",
        "merged_data = pd.merge(transactions, customers, on='CustomerID', how='left')\n",
        "\n",
        "customer_data = merged_data.groupby('CustomerID').agg({\n",
        "    'Quantity': 'sum',\n",
        "    'TotalValue': 'sum',\n",
        "    'Price': 'mean',\n",
        "}).reset_index()\n",
        "\n",
        "\n",
        "region_dummies = pd.get_dummies(customers[['CustomerID', 'Region']], columns=['Region'])\n",
        "customer_data = pd.merge(customer_data, region_dummies, on='CustomerID', how='left')\n",
        "\n",
        "\n",
        "numerical_features = ['Quantity', 'TotalValue', 'Price']\n",
        "scaler = StandardScaler()\n",
        "customer_data[numerical_features] = scaler.fit_transform(customer_data[numerical_features])\n",
        "\n",
        "\n",
        "features = customer_data[numerical_features + list(region_dummies.columns[1:])]\n",
        "\n",
        "\n",
        "db_scores = []\n",
        "k_values = range(2, 11)\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = kmeans.fit_predict(features)\n",
        "    db_index = davies_bouldin_score(features, labels)\n",
        "    db_scores.append(db_index)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, db_scores, marker='o', linestyle='--', color='b')\n",
        "plt.title(\"Davies-Bouldin Index vs. Number of Clusters\")\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Davies-Bouldin Index\")\n",
        "plt.xticks(k_values)\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "optimal_k = k_values[db_scores.index(min(db_scores))]\n",
        "print(f\"Optimal Number of Clusters: {optimal_k}\")\n",
        "\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "customer_data['Cluster'] = kmeans.fit_predict(features)\n",
        "\n",
        "\n",
        "customer_data[['CustomerID', 'Cluster']].to_csv('FirstName_LastName_Clustering.csv', index=False)\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(features)\n",
        "customer_data['PCA1'] = pca_features[:, 0]\n",
        "customer_data['PCA2'] = pca_features[:, 1]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=customer_data, palette='viridis', s=100)\n",
        "plt.title(\"Customer Segmentation (PCA Visualization)\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClustering Metrics:\")\n",
        "print(f\"Optimal Number of Clusters: {optimal_k}\")\n",
        "print(f\"Davies-Bouldin Index: {min(db_scores)}\")"
      ]
    }
  ]
}